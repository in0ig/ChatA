# 任务 6.5.1 对话界面功能测试指南

## 测试概述

这是一个**端到端真实环境测试**，使用：
- ✅ 真实的数据库表数据
- ✅ 真实的云端 Qwen AI 调用
- ✅ 真实的本地 OpenAI 模型调用
- ✅ 实际的 WebSocket 流式响应
- ✅ 完整的对话流程验证

## 测试前准备

### 1. 环境检查

```bash
# 检查后端服务
curl http://localhost:8000/health

# 检查前端服务
curl http://localhost:5173

# 检查数据库连接
cd backend
python check_real_data.py
```

### 2. 确保数据库有测试数据

```sql
-- 检查数据源
SELECT * FROM data_sources LIMIT 5;

-- 检查数据表
SELECT * FROM data_tables LIMIT 5;

-- 检查字典
SELECT * FROM dictionaries LIMIT 5;
```

### 3. 确认 AI 模型配置

```bash
# 检查 .env 文件
cat backend/.env | grep -E "QWEN|OPENAI"

# 应该看到：
# QWEN_API_KEY=your_key
# QWEN_API_URL=https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation
# OPENAI_API_KEY=your_key
# OPENAI_API_BASE=http://localhost:11434/v1  # 或其他本地模型地址
```

## 自动化测试执行

### 后端测试

```bash
cd backend

# 运行端到端测试
pytest tests/e2e/test_real_dialogue_interface.py -v -s

# 预期输出：
# ✅ test_complete_dialogue_flow_with_real_data PASSED
# ✅ test_streaming_message_display PASSED
# ✅ test_chart_auto_generation PASSED
# ✅ test_multi_round_dialogue PASSED
# ✅ test_error_handling_and_recovery PASSED
```

### 前端测试

```bash
cd frontend

# 安装 Playwright（如果还没安装）
npx playwright install

# 运行端到端测试
npx playwright test tests/e2e/dialogue-interface-real.spec.ts --headed

# 预期输出：
# ✅ 完整对话流程测试 PASSED
# ✅ 流式消息实时显示测试 PASSED
# ✅ 图表自动生成测试 PASSED
# ✅ 多轮对话测试 PASSED
# ✅ 表格和图表视图切换测试 PASSED
# ✅ 错误处理测试 PASSED
# ✅ WebSocket 连接稳定性测试 PASSED
# ✅ 响应时间测试 PASSED
```

## 手动测试场景

### 场景 1：基础对话流程

**步骤：**
1. 打开浏览器访问 `http://localhost:5173/chat`
2. 在输入框输入："最近一个月的销售额是多少？"
3. 点击"发送"按钮

**预期结果：**
- ✅ 看到灰色的"思考中"消息
- ✅ 看到"正在识别意图..."消息
- ✅ 看到"正在选择相关表..."消息
- ✅ 看到"正在生成 SQL..."消息
- ✅ 看到"正在执行查询..."消息
- ✅ 最终看到查询结果（表格或图表）
- ✅ 整个过程流畅，无卡顿

**截图位置：** `test-results/scenario-1-basic-dialogue.png`

---

### 场景 2：流式消息显示

**步骤：**
1. 输入："显示所有产品的库存情况"
2. 观察消息出现的过程

**预期结果：**
- ✅ 消息逐条出现，不是一次性显示
- ✅ 思考过程消息用灰色显示
- ✅ 最终结果用黑色显示
- ✅ 每条消息都有时间戳
- ✅ 消息顺序正确

**截图位置：** `test-results/scenario-2-streaming.png`

---

### 场景 3：图表自动生成

**步骤：**
1. 输入："按月份统计销售额趋势"
2. 等待结果

**预期结果：**
- ✅ 自动生成折线图或柱状图
- ✅ 图表有标题和坐标轴标签
- ✅ 图表数据正确
- ✅ 可以悬停查看数据点详情
- ✅ 图表响应式，大小自适应

**截图位置：** `test-results/scenario-3-chart.png`

---

### 场景 4：多轮对话

**步骤：**
1. 第一轮："查询本月销售额"
2. 等待结果
3. 第二轮："和上个月相比如何？"
4. 等待结果

**预期结果：**
- ✅ 第一轮查询成功
- ✅ 第二轮能理解"上个月"的上下文
- ✅ 第二轮自动进行数据对比
- ✅ 显示对比结果和变化趋势
- ✅ 消息历史完整保留

**截图位置：** `test-results/scenario-4-multi-round.png`

---

### 场景 5：表格和图表切换

**步骤：**
1. 输入："显示产品销售排行"
2. 等待结果
3. 点击"图表"按钮
4. 点击"表格"按钮

**预期结果：**
- ✅ 初始显示表格
- ✅ 点击"图表"后切换到图表视图
- ✅ 点击"表格"后切换回表格视图
- ✅ 切换流畅，无闪烁
- ✅ 数据保持一致

**截图位置：** `test-results/scenario-5-view-toggle.png`

---

### 场景 6：错误处理

**步骤：**
1. 输入无效问题："@#$%^&*()"
2. 观察系统反应
3. 输入正常问题："查询产品列表"

**预期结果：**
- ✅ 显示友好的错误提示
- ✅ 系统不崩溃
- ✅ 可以继续输入新问题
- ✅ 正常问题能正常处理

**截图位置：** `test-results/scenario-6-error-handling.png`

---

### 场景 7：数据追问

**步骤：**
1. 第一轮："查询销售数据"
2. 等待结果
3. 第二轮："这些数据有什么特点？"
4. 等待分析结果

**预期结果：**
- ✅ 第一轮返回数据
- ✅ 第二轮基于第一轮数据进行分析
- ✅ 分析结果包含洞察和建议
- ✅ 使用本地模型，数据不出网

**截图位置：** `test-results/scenario-7-data-followup.png`

---

### 场景 8：复杂查询

**步骤：**
1. 输入："查询最近三个月每个产品类别的销售额，并按销售额降序排列"
2. 等待结果

**预期结果：**
- ✅ 正确理解复杂查询意图
- ✅ 选择正确的表
- ✅ 生成正确的 SQL（包含 GROUP BY、ORDER BY）
- ✅ 返回正确的结果
- ✅ 自动生成合适的图表

**截图位置：** `test-results/scenario-8-complex-query.png`

---

## 性能测试

### 响应时间测试

**测试方法：**
使用浏览器开发者工具的 Network 面板

**测试指标：**
- ⏱️ 第一条思考消息响应时间：< 3 秒
- ⏱️ SQL 生成时间：< 10 秒
- ⏱️ 查询执行时间：< 5 秒
- ⏱️ 总响应时间：< 20 秒

**记录方式：**
```
测试问题：[问题内容]
思考消息时间：[X]ms
SQL生成时间：[X]ms
查询执行时间：[X]ms
总时间：[X]ms
是否达标：✅/❌
```

---

### 并发测试

**测试方法：**
1. 打开 3 个浏览器标签页
2. 同时在每个标签页发送不同的问题
3. 观察响应情况

**预期结果：**
- ✅ 所有请求都能正常响应
- ✅ 响应时间略有增加但仍在可接受范围
- ✅ 没有请求失败
- ✅ 会话隔离正确

---

## 数据安全测试

### 云端数据隔离测试

**测试方法：**
1. 查看后端日志
2. 确认发送到云端的数据

**验证点：**
- ✅ 云端只接收 Schema 信息
- ✅ 云端只接收 SQL 语句
- ✅ 云端不接收查询结果数据
- ✅ 云端不接收具体数值

**日志检查：**
```bash
# 查看云端请求日志
tail -f backend/logs/cloud_requests.log | grep -v "data_values"

# 应该只看到 Schema 和 SQL，没有实际数据
```

---

### 本地数据处理测试

**测试方法：**
1. 发送查询："查询客户信息"
2. 追问："这些客户有什么特征？"
3. 检查网络请求

**验证点：**
- ✅ 查询结果只在本地处理
- ✅ 追问不发送数据到云端
- ✅ 分析结果来自本地模型
- ✅ 网络请求中没有敏感数据

---

## 测试报告模板

### 测试执行记录

| 测试场景 | 执行时间 | 结果 | 备注 |
|---------|---------|------|------|
| 基础对话流程 | YYYY-MM-DD HH:MM | ✅/❌ | |
| 流式消息显示 | YYYY-MM-DD HH:MM | ✅/❌ | |
| 图表自动生成 | YYYY-MM-DD HH:MM | ✅/❌ | |
| 多轮对话 | YYYY-MM-DD HH:MM | ✅/❌ | |
| 表格图表切换 | YYYY-MM-DD HH:MM | ✅/❌ | |
| 错误处理 | YYYY-MM-DD HH:MM | ✅/❌ | |
| 数据追问 | YYYY-MM-DD HH:MM | ✅/❌ | |
| 复杂查询 | YYYY-MM-DD HH:MM | ✅/❌ | |

### 性能测试记录

| 指标 | 目标值 | 实际值 | 是否达标 |
|-----|--------|--------|---------|
| 思考消息响应 | < 3s | | ✅/❌ |
| SQL生成时间 | < 10s | | ✅/❌ |
| 查询执行时间 | < 5s | | ✅/❌ |
| 总响应时间 | < 20s | | ✅/❌ |

### 发现的问题

| 问题编号 | 问题描述 | 严重程度 | 状态 |
|---------|---------|---------|------|
| | | 高/中/低 | 待修复/已修复 |

### 测试结论

- **总体评价：** ✅ 通过 / ❌ 未通过
- **通过率：** X/Y (X%)
- **主要问题：** 
- **改进建议：**

---

## 验收标准

### 功能完整性
- ✅ 完整对话流程正常
- ✅ 流式消息实时显示
- ✅ 图表自动生成
- ✅ 多轮对话支持
- ✅ 错误处理完善

### 用户体验
- ✅ 界面友好易用
- ✅ 响应及时流畅
- ✅ 消息展示清晰
- ✅ 交互自然顺畅

### 性能指标
- ✅ 响应时间达标
- ✅ 并发处理正常
- ✅ 资源使用合理

### 数据安全
- ✅ 云端数据隔离
- ✅ 本地数据保护
- ✅ 隐私保护到位

---

## 附录：常见问题

### Q1: WebSocket 连接失败怎么办？
**A:** 检查后端服务是否启动，确认端口 8000 可访问

### Q2: AI 模型调用超时怎么办？
**A:** 检查 API Key 是否正确，网络是否通畅

### Q3: 图表不显示怎么办？
**A:** 检查查询结果是否适合可视化，查看浏览器控制台错误

### Q4: 多轮对话上下文丢失怎么办？
**A:** 检查会话 ID 是否正确维护，查看后端日志

---

## 测试完成检查清单

- [ ] 所有自动化测试通过
- [ ] 所有手动测试场景完成
- [ ] 性能测试达标
- [ ] 数据安全验证通过
- [ ] 测试报告已填写
- [ ] 截图已保存
- [ ] 问题已记录
- [ ] 改进建议已提出

---

**测试人员：** ___________
**测试日期：** ___________
**审核人员：** ___________
**审核日期：** ___________
